{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50eadbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "while Path.cwd().name != 'bayesian_beats_cheats':\n",
    "    os.chdir(Path.cwd().parent)\n",
    "    \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "# from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "######## TORCH ###########\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "######## Jon's code #########\n",
    "from src import preprocess\n",
    "from src.visualization import make_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39cd7b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/gnn_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "94128dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15e645bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.4.1 at http://localhost:6006/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342bccad",
   "metadata": {},
   "source": [
    "## Getting mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b4912896",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sorted(list(set(df_edge[\"NodeID1\"].tolist() + df_edge[\"NodeID2\"].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8116ae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node = df_node.sort_values(by='name').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "28f79b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2name = dict(zip(df_node.index, df_node[\"name\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6002f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id = dict(zip(df_node[\"name\"].values, df_node.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b44e7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node = pd.read_csv('data/imputed_unified_node_data.csv', keep_default_na=False)\n",
    "df_edge = pd.read_csv('data/uniq_lines_edge_weights.csv') # change to anything else later.\n",
    "\n",
    "# combine train and val together to train\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = preprocess.stratified_train_val_test_split(df_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dbe131d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_cols = ['name', 'year_of_study', 'participation', 'pe_percent',\n",
    "       'finals_percent', 'midterms_percent', 'afast', 'level_min_max',\n",
    "       'exp_min_max', 'num_videos',\n",
    "       'avg_videos_completion', 'batch_1821', 'batch_1935', 'batch_2023',\n",
    "       'major_-', 'major_Business Analytics', 'major_Chemistry',\n",
    "       'major_Computational Biology', 'major_Data Science and Analytics',\n",
    "       'major_Faculty of Arts & Social Sci', 'major_Faculty of Engineering',\n",
    "       'major_Faculty of Law', 'major_Faculty of Science',\n",
    "       'major_Life Sciences', 'major_Math/Applied Math',\n",
    "       'major_NUS Business School', 'major_Pharmacy', 'major_Physics',\n",
    "       'major_Quantitative Finance', 'major_School of Computing',\n",
    "       'major_School of Design & Environment', 'major_Statistics',\n",
    "       'major_Yong Loo Lin School (Medicine)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4313dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_kh = X_train[usable_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f3bc3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cheats = sum(y_train > 0)\n",
    "label_ratio = [len(y_train) - num_cheats, num_cheats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "331b170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14245810055865926, 0.8575418994413408]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ratio\n",
    "normWeights = [1 - (x/ sum(label_ratio)) for x in label_ratio]\n",
    "normWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01856324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider standardising edge weights DONE\n",
    "# Consider dropping some cols, DONE\n",
    "# get train, test, val mask, nodeidmapping, check.\n",
    "# Whether to standardise one-hot or not\n",
    "\n",
    "# Consider standardising edge weights.\n",
    "# Try GraphConv, and other layers, pass edge_weights\n",
    "# use weighed loss, NLL loss, different dropout shit.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f18d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Torch data specs\n",
    "# Run model for 50 epochs, see how it goes, \n",
    "\n",
    "# to try:\n",
    "# standardise edge weights\n",
    "# weights or without in loss\n",
    "# different dropout, different layernorms.\n",
    "# add lin layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f7e09",
   "metadata": {},
   "source": [
    "## Torch Geometric Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e6dc6277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 716 entries, 696 to 148\n",
      "Data columns (total 33 columns):\n",
      " #   Column                                Non-Null Count  Dtype  \n",
      "---  ------                                --------------  -----  \n",
      " 0   name                                  716 non-null    object \n",
      " 1   year_of_study                         716 non-null    int64  \n",
      " 2   participation                         716 non-null    float64\n",
      " 3   pe_percent                            716 non-null    float64\n",
      " 4   finals_percent                        716 non-null    float64\n",
      " 5   midterms_percent                      716 non-null    float64\n",
      " 6   afast                                 716 non-null    int64  \n",
      " 7   level_min_max                         716 non-null    float64\n",
      " 8   exp_min_max                           716 non-null    float64\n",
      " 9   num_videos                            716 non-null    int64  \n",
      " 10  avg_videos_completion                 716 non-null    float64\n",
      " 11  batch_1821                            716 non-null    int64  \n",
      " 12  batch_1935                            716 non-null    int64  \n",
      " 13  batch_2023                            716 non-null    int64  \n",
      " 14  major_-                               716 non-null    int64  \n",
      " 15  major_Business Analytics              716 non-null    int64  \n",
      " 16  major_Chemistry                       716 non-null    int64  \n",
      " 17  major_Computational Biology           716 non-null    int64  \n",
      " 18  major_Data Science and Analytics      716 non-null    int64  \n",
      " 19  major_Faculty of Arts & Social Sci    716 non-null    int64  \n",
      " 20  major_Faculty of Engineering          716 non-null    int64  \n",
      " 21  major_Faculty of Law                  716 non-null    int64  \n",
      " 22  major_Faculty of Science              716 non-null    int64  \n",
      " 23  major_Life Sciences                   716 non-null    int64  \n",
      " 24  major_Math/Applied Math               716 non-null    int64  \n",
      " 25  major_NUS Business School             716 non-null    int64  \n",
      " 26  major_Pharmacy                        716 non-null    int64  \n",
      " 27  major_Physics                         716 non-null    int64  \n",
      " 28  major_Quantitative Finance            716 non-null    int64  \n",
      " 29  major_School of Computing             716 non-null    int64  \n",
      " 30  major_School of Design & Environment  716 non-null    int64  \n",
      " 31  major_Statistics                      716 non-null    int64  \n",
      " 32  major_Yong Loo Lin School (Medicine)  716 non-null    int64  \n",
      "dtypes: float64(7), int64(25), object(1)\n",
      "memory usage: 206.4+ KB\n"
     ]
    }
   ],
   "source": [
    "X_train_kh.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee86d9dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-f33a361b3494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_kh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "data_features = torch.tensor(X_train_kh.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77769556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b41bd3f",
   "metadata": {},
   "source": [
    "## SAGE and GCNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91b03cf",
   "metadata": {},
   "source": [
    "### Customized Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.nn as pyg_nn\n",
    "import torch_geometric.utils as pyg_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8888d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomConv(pyg_nn.MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(CustomConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.lin = nn.Linear(in_channels, out_channels)\n",
    "        self.lin_self = nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels] # number of nodes, \n",
    "        # edge_index has shape [2, E] # every edge 2 nodes, number of edges\n",
    "\n",
    "        # Add self-loops to the adjacency matrix.\n",
    "        # add_self_loops(edge_index, num_nodes = x.size(0))\n",
    "        edge_index, _ = pyg_utils.remove_self_loops(edge_index)\n",
    "\n",
    "        # Transform node feature matrix.\n",
    "        self_x = self.lin_self(x)\n",
    "        #x = self.lin(x)\n",
    "        \n",
    "        # return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "        return self_x + self.propagate(edge_index, size=(x.size(0), x.size(0)), x=self.lin(x))\n",
    "\n",
    "    def message(self, x_i, x_j, edge_index, size):\n",
    "        # Compute messages\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        row, col = edge_index\n",
    "        deg = pyg_utils.degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "        # GRAPHSAGE, normalize after message passing.\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6471f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GCNNs\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(dataset.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5340_env",
   "language": "python",
   "name": "cs5340_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
