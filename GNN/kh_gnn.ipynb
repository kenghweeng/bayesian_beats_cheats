{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b974b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "while Path.cwd().name != 'bayesian_beats_cheats':\n",
    "    os.chdir(Path.cwd().parent)\n",
    "    \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "# from tensorboardX import SummaryWriter\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "######## TORCH ###########\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "######## Jon's code #########\n",
    "from src import preprocess\n",
    "from src.visualization import make_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fd03219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU = 8,13\n",
    "\n",
    "# gpu_list = ''\n",
    "# multi_gpus=False\n",
    "# if isinstance(GPU, int):\n",
    "#     gpu_list = str(GPU)\n",
    "# else:\n",
    "#     multi_gpus = True\n",
    "#     for i, gpu_id in enumerate(GPU):\n",
    "#         gpu_list += str(gpu_id)\n",
    "#         if i != len(GPU) - 1:\n",
    "#             gpu_list += ','\n",
    "#     os.environ['CUDA_VISIBLE_DEVICES'] = gpu_list\n",
    "#     print(gpu_list)\n",
    "\n",
    "device = torch.device(\"cuda:8\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1dc8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afe482e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorboard/compat/__init__.py\", line 46, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kenghwee/cs5340_proj/env/bin/tensorboard\", line 8, in <module>\n",
      "    sys.exit(run_main())\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorboard/main.py\", line 58, in run_main\n",
      "    if getattr(tf, \"__version__\", \"stub\") == \"stub\":\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorboard/lazy.py\", line 68, in __getattr__\n",
      "    return getattr(load_once(self), attr_name)\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorboard/lazy.py\", line 100, in wrapper\n",
      "    cache[arg] = f(arg)\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorboard/lazy.py\", line 53, in load_once\n",
      "    module = load_fn()\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorboard/compat/__init__.py\", line 49, in tf\n",
      "    import tensorflow\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorflow/__init__.py\", line 41, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorflow/python/__init__.py\", line 48, in <module>\n",
      "    from tensorflow.python import keras\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorflow/python/keras/__init__.py\", line 27, in <module>\n",
      "    from tensorflow.python.keras import models\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorflow/python/keras/models.py\", line 26, in <module>\n",
      "    from tensorflow.python.keras.engine import functional\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\", line 38, in <module>\n",
      "    from tensorflow.python.keras.engine import training as training_lib\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\", line 52, in <module>\n",
      "    from tensorflow.python.keras.engine import data_adapter\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 65, in <module>\n",
      "    import pandas as pd  # pylint: disable=g-import-not-at-top\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/pandas/__init__.py\", line 51, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/pandas/core/api.py\", line 31, in <module>\n",
      "    from pandas.core.groupby import Grouper, NamedAgg\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/pandas/core/groupby/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.groupby.generic import DataFrameGroupBy, NamedAgg, SeriesGroupBy\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/pandas/core/groupby/generic.py\", line 68, in <module>\n",
      "    from pandas.core.groupby.groupby import (\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\", line 1284, in <module>\n",
      "    class GroupBy(BaseGroupBy[FrameOrSeries]):\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\", line 1675, in GroupBy\n",
      "    def max(self, numeric_only: bool = False, min_count: int = -1):\n",
      "  File \"/home/kenghwee/cs5340_proj/env/lib/python3.8/site-packages/pandas/util/_decorators.py\", line 376, in decorator\n",
      "    [\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ddf56b",
   "metadata": {},
   "source": [
    "## Getting mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4603e294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node = pd.read_csv('data/imputed_unified_node_data.csv', keep_default_na=False)\n",
    "df_edge = pd.read_csv('data/uniq_lines_edge_weights.csv') # change to anything else later.\n",
    "\n",
    "# combine train and val together to train\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = preprocess.stratified_train_val_test_split(df_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd3e7e6",
   "metadata": {},
   "source": [
    "### Generating y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "275db972",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.concat([y_train, y_val, y_test]).sort_index()\n",
    "y = y.apply(lambda x: 1 if x>0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5d02058",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2name = dict(zip(df_node.index, df_node[\"name\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9110c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id = dict(zip(df_node[\"name\"].values, df_node.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbe0e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_cols = ['year_of_study',\n",
    " 'participation',\n",
    " 'pe_percent',\n",
    " 'finals_percent',\n",
    " 'midterms_percent',\n",
    " 'afast',\n",
    " 'level_min_max',\n",
    " 'exp_min_max',\n",
    " 'num_videos',\n",
    " 'avg_videos_completion',\n",
    " 'batch_1821',\n",
    " 'batch_1935',\n",
    " 'batch_2023',\n",
    " 'major_-',\n",
    " 'major_Business Analytics',\n",
    " 'major_Chemistry',\n",
    " 'major_Computational Biology',\n",
    " 'major_Data Science and Analytics',\n",
    " 'major_Faculty of Arts & Social Sci',\n",
    " 'major_Faculty of Engineering',\n",
    " 'major_Faculty of Law',\n",
    " 'major_Faculty of Science',\n",
    " 'major_Life Sciences',\n",
    " 'major_Math/Applied Math',\n",
    " 'major_NUS Business School',\n",
    " 'major_Pharmacy',\n",
    " 'major_Physics',\n",
    " 'major_Quantitative Finance',\n",
    " 'major_School of Computing',\n",
    " 'major_School of Design & Environment',\n",
    " 'major_Statistics',\n",
    " 'major_Yong Loo Lin School (Medicine)']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2c3677",
   "metadata": {},
   "source": [
    "### Generating features and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8508f00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node = df_node[usable_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2d350a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "df_node_kh = mm_scaler.fit_transform(df_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297bb59",
   "metadata": {},
   "source": [
    "### Generating node masks for train, val, test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1cb71e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = df_node.index.isin(X_train.index)\n",
    "val_mask = df_node.index.isin(X_val.index)\n",
    "test_mask = df_node.index.isin(X_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee200da",
   "metadata": {},
   "source": [
    "### Generating edge index and edge weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f2d54ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge[\"NodeID1_Num\"] = df_edge[\"NodeID1\"].map(name2id)\n",
    "df_edge[\"NodeID2_Num\"] = df_edge[\"NodeID2\"].map(name2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "731a758e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NodeID1</th>\n",
       "      <th>NodeID2</th>\n",
       "      <th>edge_weights</th>\n",
       "      <th>NodeID1_Num</th>\n",
       "      <th>NodeID2_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aaron_christian</td>\n",
       "      <td>marc_key</td>\n",
       "      <td>0.476504</td>\n",
       "      <td>21</td>\n",
       "      <td>957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaron_christian</td>\n",
       "      <td>joseph_trevino</td>\n",
       "      <td>0.329899</td>\n",
       "      <td>21</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaron_pope</td>\n",
       "      <td>annette_solis</td>\n",
       "      <td>0.347540</td>\n",
       "      <td>683</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aaron_pope</td>\n",
       "      <td>carol_harris</td>\n",
       "      <td>0.419707</td>\n",
       "      <td>683</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aaron_powell</td>\n",
       "      <td>jennifer_simmons</td>\n",
       "      <td>0.366710</td>\n",
       "      <td>437</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3382</th>\n",
       "      <td>zachary_beasley</td>\n",
       "      <td>robert_lopez</td>\n",
       "      <td>0.481366</td>\n",
       "      <td>244</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3383</th>\n",
       "      <td>zachary_beasley</td>\n",
       "      <td>steven_adams</td>\n",
       "      <td>0.676140</td>\n",
       "      <td>244</td>\n",
       "      <td>622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3384</th>\n",
       "      <td>zachary_carter</td>\n",
       "      <td>richard_higgins</td>\n",
       "      <td>0.362905</td>\n",
       "      <td>53</td>\n",
       "      <td>718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>zachary_hernandez</td>\n",
       "      <td>thomas_barnes</td>\n",
       "      <td>1.284771</td>\n",
       "      <td>958</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>zachary_hernandez</td>\n",
       "      <td>denise_brooks</td>\n",
       "      <td>0.503708</td>\n",
       "      <td>958</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3387 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                NodeID1           NodeID2  edge_weights  NodeID1_Num  \\\n",
       "0       aaron_christian          marc_key      0.476504           21   \n",
       "1       aaron_christian    joseph_trevino      0.329899           21   \n",
       "2            aaron_pope     annette_solis      0.347540          683   \n",
       "3            aaron_pope      carol_harris      0.419707          683   \n",
       "4          aaron_powell  jennifer_simmons      0.366710          437   \n",
       "...                 ...               ...           ...          ...   \n",
       "3382    zachary_beasley      robert_lopez      0.481366          244   \n",
       "3383    zachary_beasley      steven_adams      0.676140          244   \n",
       "3384     zachary_carter   richard_higgins      0.362905           53   \n",
       "3385  zachary_hernandez     thomas_barnes      1.284771          958   \n",
       "3386  zachary_hernandez     denise_brooks      0.503708          958   \n",
       "\n",
       "      NodeID2_Num  \n",
       "0             957  \n",
       "1             129  \n",
       "2             866  \n",
       "3             336  \n",
       "4             865  \n",
       "...           ...  \n",
       "3382           17  \n",
       "3383          622  \n",
       "3384          718  \n",
       "3385          868  \n",
       "3386          993  \n",
       "\n",
       "[3387 rows x 5 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "728bf313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edge_index = df_edge[[\"NodeID1_Num\", \"NodeID2_Num\"]].values.tolist()\n",
    "df_edge_weights = df_edge[\"edge_weights\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6b5c4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_edge_index = [list(reversed(x)) for x in df_edge_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0405819",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = list(zip(df_edge_index + reverse_edge_index, df_edge_weights * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "960473ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index, edge_weights = [], []\n",
    "for edge, weight in lst:\n",
    "    edge_index.append(edge)\n",
    "    edge_weights.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b53f0a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.7       , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.7       , 0.73333333, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.7       , 0.9       , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.74      , 0.6225    , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.74      , 0.64916667, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.11111111, 0.66      , 0.455     , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_node_kh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4215b91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x = torch.tensor(df_node_kh, dtype=torch.float)\n",
    "final_train_mask = torch.tensor(train_mask, dtype=torch.bool)\n",
    "final_val_mask = torch.tensor(val_mask, dtype=torch.bool)\n",
    "final_test_mask = torch.tensor(test_mask, dtype=torch.bool)\n",
    "final_y = torch.tensor(y.values, dtype=torch.int64)\n",
    "final_edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "final_edge_weights = torch.tensor(edge_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "68fff8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x=final_x, train_mask=final_train_mask, val_mask=final_val_mask, test_mask=final_test_mask,\n",
    "           y=final_y, edge_index=final_edge_index.t().contiguous(), edge_weight=final_edge_weights.t(),\n",
    "           num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a181e36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44fd91a",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b55debed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 1024\n",
      "Number of edges: 6774\n",
      "Average node degree: 6.62\n",
      "Number of training nodes: 716\n",
      "Training node label rate: 0.70\n",
      "Contains isolated nodes: False\n",
      "Contains self-loops: False\n",
      "Is undirected: True\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')\n",
    "print(f'Contains isolated nodes: {data.contains_isolated_nodes()}')\n",
    "print(f'Contains self-loops: {data.contains_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "print(f'Number of classes: {data.num_classes}')\n",
    "\n",
    "# put all infor in device cuda, use multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a95848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Verified with CORA benchmark dataset specifications to ensure correctness.\n",
    "\n",
    "# from torch_geometric.datasets import Planetoid\n",
    "# from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "# dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "\n",
    "# print()\n",
    "# print(f'Dataset: {dataset}:')\n",
    "\n",
    "# for key, item in dataset[0]:\n",
    "#     print(\"{} found in data\".format(key))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed7733",
   "metadata": {},
   "source": [
    "### Get Weight Ratio for weight labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "911c10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cheats = sum(y > 0)\n",
    "label_ratio = [len(y) - num_cheats, num_cheats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "983f3a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "normWeights = [1 - (x/sum(label_ratio)) for x in label_ratio]\n",
    "normWeights = torch.FloatTensor(normWeights).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da7d4c",
   "metadata": {},
   "source": [
    "## GCN Baseline\n",
    "Ensure code is running properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3d22a913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(32, 16)\n",
      "  (conv2): GCNConv(16, 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(data.num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, data.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.conv1(x, edge_index, edge_weight)\n",
    "        x = x.relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        return x\n",
    "\n",
    "model = GCN(hidden_channels=16)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d4ab1",
   "metadata": {},
   "source": [
    "### Baseline training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d591ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(hidden_channels=16).to(device)\n",
    "# model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "866b0755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.7023\n",
      "Epoch: 002, Loss: 0.6948\n",
      "Epoch: 003, Loss: 0.6885\n",
      "Epoch: 004, Loss: 0.6937\n",
      "Epoch: 005, Loss: 0.6883\n",
      "Epoch: 006, Loss: 0.6874\n",
      "Epoch: 007, Loss: 0.6907\n",
      "Epoch: 008, Loss: 0.6860\n",
      "Epoch: 009, Loss: 0.6827\n",
      "Epoch: 010, Loss: 0.6862\n",
      "Epoch: 011, Loss: 0.6819\n",
      "Epoch: 012, Loss: 0.6846\n",
      "Epoch: 013, Loss: 0.6794\n",
      "Epoch: 014, Loss: 0.6797\n",
      "Epoch: 015, Loss: 0.6910\n",
      "Epoch: 016, Loss: 0.6855\n",
      "Epoch: 017, Loss: 0.6823\n",
      "Epoch: 018, Loss: 0.6829\n",
      "Epoch: 019, Loss: 0.6807\n",
      "Epoch: 020, Loss: 0.6785\n",
      "Epoch: 021, Loss: 0.6780\n",
      "Epoch: 022, Loss: 0.6749\n",
      "Epoch: 023, Loss: 0.6704\n",
      "Epoch: 024, Loss: 0.6681\n",
      "Epoch: 025, Loss: 0.6726\n",
      "Epoch: 026, Loss: 0.6782\n",
      "Epoch: 027, Loss: 0.6701\n",
      "Epoch: 028, Loss: 0.6682\n",
      "Epoch: 029, Loss: 0.6688\n",
      "Epoch: 030, Loss: 0.6703\n",
      "Epoch: 031, Loss: 0.6608\n",
      "Epoch: 032, Loss: 0.6794\n",
      "Epoch: 033, Loss: 0.6623\n",
      "Epoch: 034, Loss: 0.6626\n",
      "Epoch: 035, Loss: 0.6689\n",
      "Epoch: 036, Loss: 0.6560\n",
      "Epoch: 037, Loss: 0.6600\n",
      "Epoch: 038, Loss: 0.6536\n",
      "Epoch: 039, Loss: 0.6558\n",
      "Epoch: 040, Loss: 0.6589\n",
      "Epoch: 041, Loss: 0.6565\n",
      "Epoch: 042, Loss: 0.6601\n",
      "Epoch: 043, Loss: 0.6537\n",
      "Epoch: 044, Loss: 0.6485\n",
      "Epoch: 045, Loss: 0.6511\n",
      "Epoch: 046, Loss: 0.6534\n",
      "Epoch: 047, Loss: 0.6522\n",
      "Epoch: 048, Loss: 0.6406\n",
      "Epoch: 049, Loss: 0.6494\n",
      "Epoch: 050, Loss: 0.6466\n",
      "Epoch: 051, Loss: 0.6375\n",
      "Epoch: 052, Loss: 0.6442\n",
      "Epoch: 053, Loss: 0.6391\n",
      "Epoch: 054, Loss: 0.6452\n",
      "Epoch: 055, Loss: 0.6478\n",
      "Epoch: 056, Loss: 0.6417\n",
      "Epoch: 057, Loss: 0.6318\n",
      "Epoch: 058, Loss: 0.6290\n",
      "Epoch: 059, Loss: 0.6352\n",
      "Epoch: 060, Loss: 0.6242\n",
      "Epoch: 061, Loss: 0.6199\n",
      "Epoch: 062, Loss: 0.6382\n",
      "Epoch: 063, Loss: 0.6202\n",
      "Epoch: 064, Loss: 0.6249\n",
      "Epoch: 065, Loss: 0.6197\n",
      "Epoch: 066, Loss: 0.6140\n",
      "Epoch: 067, Loss: 0.6301\n",
      "Epoch: 068, Loss: 0.6226\n",
      "Epoch: 069, Loss: 0.6289\n",
      "Epoch: 070, Loss: 0.6344\n",
      "Epoch: 071, Loss: 0.6104\n",
      "Epoch: 072, Loss: 0.6123\n",
      "Epoch: 073, Loss: 0.6227\n",
      "Epoch: 074, Loss: 0.6241\n",
      "Epoch: 075, Loss: 0.6174\n",
      "Epoch: 076, Loss: 0.6248\n",
      "Epoch: 077, Loss: 0.6107\n",
      "Epoch: 078, Loss: 0.6170\n",
      "Epoch: 079, Loss: 0.6096\n",
      "Epoch: 080, Loss: 0.6035\n",
      "Epoch: 081, Loss: 0.6084\n",
      "Epoch: 082, Loss: 0.6103\n",
      "Epoch: 083, Loss: 0.6154\n",
      "Epoch: 084, Loss: 0.6113\n",
      "Epoch: 085, Loss: 0.6258\n",
      "Epoch: 086, Loss: 0.6121\n",
      "Epoch: 087, Loss: 0.6098\n",
      "Epoch: 088, Loss: 0.6100\n",
      "Epoch: 089, Loss: 0.6025\n",
      "Epoch: 090, Loss: 0.6020\n",
      "Epoch: 091, Loss: 0.6132\n",
      "Epoch: 092, Loss: 0.6033\n",
      "Epoch: 093, Loss: 0.6072\n",
      "Epoch: 094, Loss: 0.6084\n",
      "Epoch: 095, Loss: 0.5844\n",
      "Epoch: 096, Loss: 0.6036\n",
      "Epoch: 097, Loss: 0.6189\n",
      "Epoch: 098, Loss: 0.6020\n",
      "Epoch: 099, Loss: 0.5949\n",
      "Epoch: 100, Loss: 0.6042\n",
      "Epoch: 101, Loss: 0.5948\n",
      "Epoch: 102, Loss: 0.5977\n",
      "Epoch: 103, Loss: 0.5905\n",
      "Epoch: 104, Loss: 0.6011\n",
      "Epoch: 105, Loss: 0.5977\n",
      "Epoch: 106, Loss: 0.5859\n",
      "Epoch: 107, Loss: 0.5995\n",
      "Epoch: 108, Loss: 0.5947\n",
      "Epoch: 109, Loss: 0.5880\n",
      "Epoch: 110, Loss: 0.5930\n",
      "Epoch: 111, Loss: 0.5951\n",
      "Epoch: 112, Loss: 0.5933\n",
      "Epoch: 113, Loss: 0.5875\n",
      "Epoch: 114, Loss: 0.5831\n",
      "Epoch: 115, Loss: 0.6012\n",
      "Epoch: 116, Loss: 0.5865\n",
      "Epoch: 117, Loss: 0.5898\n",
      "Epoch: 118, Loss: 0.5876\n",
      "Epoch: 119, Loss: 0.6061\n",
      "Epoch: 120, Loss: 0.5680\n",
      "Epoch: 121, Loss: 0.5803\n",
      "Epoch: 122, Loss: 0.5916\n",
      "Epoch: 123, Loss: 0.5868\n",
      "Epoch: 124, Loss: 0.5804\n",
      "Epoch: 125, Loss: 0.5934\n",
      "Epoch: 126, Loss: 0.6032\n",
      "Epoch: 127, Loss: 0.5938\n",
      "Epoch: 128, Loss: 0.5953\n",
      "Epoch: 129, Loss: 0.5825\n",
      "Epoch: 130, Loss: 0.5689\n",
      "Epoch: 131, Loss: 0.5820\n",
      "Epoch: 132, Loss: 0.5876\n",
      "Epoch: 133, Loss: 0.5776\n",
      "Epoch: 134, Loss: 0.5749\n",
      "Epoch: 135, Loss: 0.5842\n",
      "Epoch: 136, Loss: 0.5792\n",
      "Epoch: 137, Loss: 0.5898\n",
      "Epoch: 138, Loss: 0.5764\n",
      "Epoch: 139, Loss: 0.5754\n",
      "Epoch: 140, Loss: 0.5742\n",
      "Epoch: 141, Loss: 0.5800\n",
      "Epoch: 142, Loss: 0.6099\n",
      "Epoch: 143, Loss: 0.5671\n",
      "Epoch: 144, Loss: 0.5735\n",
      "Epoch: 145, Loss: 0.5863\n",
      "Epoch: 146, Loss: 0.5702\n",
      "Epoch: 147, Loss: 0.5744\n",
      "Epoch: 148, Loss: 0.5624\n",
      "Epoch: 149, Loss: 0.5890\n",
      "Epoch: 150, Loss: 0.5712\n",
      "Epoch: 151, Loss: 0.5728\n",
      "Epoch: 152, Loss: 0.5882\n",
      "Epoch: 153, Loss: 0.5664\n",
      "Epoch: 154, Loss: 0.5787\n",
      "Epoch: 155, Loss: 0.5921\n",
      "Epoch: 156, Loss: 0.5560\n",
      "Epoch: 157, Loss: 0.5743\n",
      "Epoch: 158, Loss: 0.5655\n",
      "Epoch: 159, Loss: 0.5649\n",
      "Epoch: 160, Loss: 0.5621\n",
      "Epoch: 161, Loss: 0.5570\n",
      "Epoch: 162, Loss: 0.5697\n",
      "Epoch: 163, Loss: 0.5765\n",
      "Epoch: 164, Loss: 0.5747\n",
      "Epoch: 165, Loss: 0.5663\n",
      "Epoch: 166, Loss: 0.5712\n",
      "Epoch: 167, Loss: 0.5531\n",
      "Epoch: 168, Loss: 0.5699\n",
      "Epoch: 169, Loss: 0.5605\n",
      "Epoch: 170, Loss: 0.5830\n",
      "Epoch: 171, Loss: 0.5549\n",
      "Epoch: 172, Loss: 0.5667\n",
      "Epoch: 173, Loss: 0.5911\n",
      "Epoch: 174, Loss: 0.5686\n",
      "Epoch: 175, Loss: 0.5728\n",
      "Epoch: 176, Loss: 0.5647\n",
      "Epoch: 177, Loss: 0.5618\n",
      "Epoch: 178, Loss: 0.5686\n",
      "Epoch: 179, Loss: 0.5445\n",
      "Epoch: 180, Loss: 0.5654\n",
      "Epoch: 181, Loss: 0.5603\n",
      "Epoch: 182, Loss: 0.5685\n",
      "Epoch: 183, Loss: 0.5561\n",
      "Epoch: 184, Loss: 0.5541\n",
      "Epoch: 185, Loss: 0.5652\n",
      "Epoch: 186, Loss: 0.5419\n",
      "Epoch: 187, Loss: 0.5697\n",
      "Epoch: 188, Loss: 0.5497\n",
      "Epoch: 189, Loss: 0.5630\n",
      "Epoch: 190, Loss: 0.5515\n",
      "Epoch: 191, Loss: 0.5609\n",
      "Epoch: 192, Loss: 0.5485\n",
      "Epoch: 193, Loss: 0.5475\n",
      "Epoch: 194, Loss: 0.5732\n",
      "Epoch: 195, Loss: 0.5600\n",
      "Epoch: 196, Loss: 0.5559\n",
      "Epoch: 197, Loss: 0.5581\n",
      "Epoch: 198, Loss: 0.5559\n",
      "Epoch: 199, Loss: 0.5625\n",
      "Epoch: 200, Loss: 0.5543\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=normWeights)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()  # Clear gradients.\n",
    "    out = model(data.x, data.edge_index, data.edge_weight)  # Perform a single forward pass.\n",
    "    loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "    loss.backward()  # Derive gradients.\n",
    "    optimizer.step()  # Update parameters based on gradients.\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index, data.edge_weight)\n",
    "    pred = out.cpu().argmax(dim=1)  # Use the class with highest probability.\n",
    "#     print(pred.tolist())\n",
    "    test_correct = pred[data.val_mask] == data.y.cpu()[data.val_mask]  # Check against ground-truth labels.\n",
    "    cf = confusion_matrix(data.y.cpu()[data.val_mask], pred[data.val_mask])\n",
    "    make_confusion_matrix(cf)\n",
    "    test_acc = int(test_correct.sum()) / int(data.val_mask.sum())  # Derive ratio of correct predictions.\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    loss = train().tolist()\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e602a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5951\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_acc = test()\n",
    "print(f'Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769895cd",
   "metadata": {},
   "source": [
    "### Refined Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "0d7bf363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch_geometric.nn as pyg_nn\n",
    "# import torch_geometric.utils as pyg_utils\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d4be61e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNStack(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNStack, self).__init__()\n",
    "        self.curr_dim = hidden_dim\n",
    "        self.convs = nn.ModuleList()\n",
    "        self.convs.append(self.build_conv_model(input_dim, self.curr_dim))\n",
    "        self.lns = nn.ModuleList()\n",
    "        self.lns.append(nn.LayerNorm(self.curr_dim))\n",
    "        for l in range(2):\n",
    "            old_dim = self.curr_dim\n",
    "            self.curr_dim = old_dim // 2\n",
    "            self.convs.append(self.build_conv_model(old_dim, self.curr_dim))\n",
    "            self.lns.append(nn.LayerNorm(self.curr_dim))\n",
    "        # post-message-passing (optional)\n",
    "        self.post_mp = nn.Sequential(\n",
    "            nn.Linear(self.curr_dim, self.curr_dim), nn.Dropout(0.3), \n",
    "            nn.Linear(self.curr_dim, output_dim))\n",
    "\n",
    "        self.dropout = 0.3\n",
    "        self.num_layers = 3\n",
    "\n",
    "    def build_conv_model(self, input_dim, hidden_dim):\n",
    "        return GCNConv(input_dim, hidden_dim)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_weight = data.x, data.edge_index, data.edge_weight\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.convs[i](x, edge_index, edge_weight)\n",
    "#             emb = x\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            if not i == self.num_layers - 1: # linear xform\n",
    "                x = self.lns[i](x)\n",
    "\n",
    "        x = self.post_mp(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "caf621bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNStack(data.num_node_features, 16, data.num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=normWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a0c14b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/gnn_\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "981ebbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1dc42159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, writer):\n",
    "    # train\n",
    "    for epoch in range(1000):\n",
    "        model.train()   \n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        curr_loss = loss.tolist()\n",
    "        writer.add_scalar(\"loss\", curr_loss, epoch)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            test_acc, test_f1 = test(model, is_validation=True)\n",
    "            print(\"Epoch {}. Loss: {:.4f}. Test accuracy: {:.4f}. Test F1: {:.4f}\".format(\n",
    "                epoch, curr_loss, test_acc, test_f1))\n",
    "            writer.add_scalar(\"test accuracy\", test_acc, epoch)\n",
    "            writer.add_scalar(\"test_F1\", test_f1, epoch)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "35c8a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, is_validation=True):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        pred = model(data)\n",
    "        pred = pred.cpu().argmax(dim=1)\n",
    "\n",
    "        mask = data.val_mask if is_validation else data.test_mask\n",
    "        # node classification: only evaluate on nodes in test set\n",
    "        pred = pred[mask]\n",
    "        label = data.y.cpu()[mask]\n",
    "            \n",
    "    correct += pred.eq(label).sum().item()\n",
    "    total = mask.sum()\n",
    "    \n",
    "    f1 = f1_score(pred, label)\n",
    "    return (correct / total), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "341367d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 0.7689. Test accuracy: 0.8585. Test F1: 0.0000\n",
      "Epoch 10. Loss: 0.7015. Test accuracy: 0.8585. Test F1: 0.0645\n",
      "Epoch 20. Loss: 0.6967. Test accuracy: 0.1415. Test F1: 0.2479\n",
      "Epoch 30. Loss: 0.6978. Test accuracy: 0.1415. Test F1: 0.2348\n",
      "Epoch 40. Loss: 0.6923. Test accuracy: 0.8585. Test F1: 0.0000\n",
      "Epoch 50. Loss: 0.6932. Test accuracy: 0.8585. Test F1: 0.0000\n",
      "Epoch 60. Loss: 0.6940. Test accuracy: 0.3073. Test F1: 0.2526\n",
      "Epoch 70. Loss: 0.6923. Test accuracy: 0.2293. Test F1: 0.2617\n",
      "Epoch 80. Loss: 0.6923. Test accuracy: 0.8585. Test F1: 0.0000\n",
      "Epoch 90. Loss: 0.6930. Test accuracy: 0.8390. Test F1: 0.0571\n",
      "Epoch 100. Loss: 0.6926. Test accuracy: 0.8049. Test F1: 0.0476\n",
      "Epoch 110. Loss: 0.6937. Test accuracy: 0.7268. Test F1: 0.2432\n",
      "Epoch 120. Loss: 0.6933. Test accuracy: 0.8585. Test F1: 0.0000\n",
      "Epoch 130. Loss: 0.6935. Test accuracy: 0.8585. Test F1: 0.0000\n",
      "Epoch 140. Loss: 0.6930. Test accuracy: 0.8488. Test F1: 0.0606\n",
      "Epoch 150. Loss: 0.6925. Test accuracy: 0.6293. Test F1: 0.2083\n",
      "Epoch 160. Loss: 0.6926. Test accuracy: 0.6634. Test F1: 0.2418\n",
      "Epoch 170. Loss: 0.6944. Test accuracy: 0.1366. Test F1: 0.2403\n",
      "Epoch 180. Loss: 0.6941. Test accuracy: 0.8585. Test F1: 0.0000\n",
      "Epoch 190. Loss: 0.6935. Test accuracy: 0.1512. Test F1: 0.2500\n",
      "Epoch 200. Loss: 0.6909. Test accuracy: 0.1561. Test F1: 0.2511\n",
      "Epoch 210. Loss: 0.6877. Test accuracy: 0.2585. Test F1: 0.2245\n",
      "Epoch 220. Loss: 0.6886. Test accuracy: 0.1610. Test F1: 0.2321\n",
      "Epoch 230. Loss: 0.6925. Test accuracy: 0.3220. Test F1: 0.2404\n",
      "Epoch 240. Loss: 0.6865. Test accuracy: 0.3756. Test F1: 0.2558\n",
      "Epoch 250. Loss: 0.6929. Test accuracy: 0.2390. Test F1: 0.2500\n",
      "Epoch 260. Loss: 0.6915. Test accuracy: 0.2390. Test F1: 0.2500\n",
      "Epoch 270. Loss: 0.6859. Test accuracy: 0.3951. Test F1: 0.2530\n",
      "Epoch 280. Loss: 0.6808. Test accuracy: 0.3073. Test F1: 0.2526\n",
      "Epoch 290. Loss: 0.6920. Test accuracy: 0.1707. Test F1: 0.2544\n",
      "Epoch 300. Loss: 0.6874. Test accuracy: 0.3854. Test F1: 0.2125\n",
      "Epoch 310. Loss: 0.6751. Test accuracy: 0.3463. Test F1: 0.2556\n",
      "Epoch 320. Loss: 0.6922. Test accuracy: 0.1902. Test F1: 0.2523\n",
      "Epoch 330. Loss: 0.6768. Test accuracy: 0.6000. Test F1: 0.2115\n",
      "Epoch 340. Loss: 0.6687. Test accuracy: 0.2293. Test F1: 0.2617\n",
      "Epoch 350. Loss: 0.6537. Test accuracy: 0.2585. Test F1: 0.2621\n",
      "Epoch 360. Loss: 0.6739. Test accuracy: 0.3463. Test F1: 0.2796\n",
      "Epoch 370. Loss: 0.6821. Test accuracy: 0.2634. Test F1: 0.2705\n",
      "Epoch 380. Loss: 0.6624. Test accuracy: 0.3854. Test F1: 0.2410\n",
      "Epoch 390. Loss: 0.6570. Test accuracy: 0.3951. Test F1: 0.2346\n",
      "Epoch 400. Loss: 0.6521. Test accuracy: 0.3902. Test F1: 0.2424\n",
      "Epoch 410. Loss: 0.6344. Test accuracy: 0.3902. Test F1: 0.2515\n",
      "Epoch 420. Loss: 0.6525. Test accuracy: 0.4098. Test F1: 0.2577\n",
      "Epoch 430. Loss: 0.6516. Test accuracy: 0.4780. Test F1: 0.2517\n",
      "Epoch 440. Loss: 0.6608. Test accuracy: 0.3707. Test F1: 0.2543\n",
      "Epoch 450. Loss: 0.6484. Test accuracy: 0.3415. Test F1: 0.2458\n",
      "Epoch 460. Loss: 0.6345. Test accuracy: 0.3561. Test F1: 0.2584\n",
      "Epoch 470. Loss: 0.6326. Test accuracy: 0.4390. Test F1: 0.2675\n",
      "Epoch 480. Loss: 0.6295. Test accuracy: 0.3463. Test F1: 0.2717\n",
      "Epoch 490. Loss: 0.6636. Test accuracy: 0.4244. Test F1: 0.2338\n",
      "Epoch 500. Loss: 0.6451. Test accuracy: 0.3073. Test F1: 0.2283\n",
      "Epoch 510. Loss: 0.6855. Test accuracy: 0.1805. Test F1: 0.2566\n",
      "Epoch 520. Loss: 0.6901. Test accuracy: 0.5951. Test F1: 0.2523\n",
      "Epoch 530. Loss: 0.6927. Test accuracy: 0.8585. Test F1: 0.0000\n",
      "Epoch 540. Loss: 0.6910. Test accuracy: 0.1610. Test F1: 0.2522\n",
      "Epoch 550. Loss: 0.6915. Test accuracy: 0.1707. Test F1: 0.2544\n",
      "Epoch 560. Loss: 0.6901. Test accuracy: 0.6634. Test F1: 0.1882\n",
      "Epoch 570. Loss: 0.6893. Test accuracy: 0.1610. Test F1: 0.2522\n",
      "Epoch 580. Loss: 0.6921. Test accuracy: 0.4244. Test F1: 0.2436\n",
      "Epoch 590. Loss: 0.6897. Test accuracy: 0.3854. Test F1: 0.2317\n",
      "Epoch 600. Loss: 0.6814. Test accuracy: 0.2439. Test F1: 0.2439\n",
      "Epoch 610. Loss: 0.6849. Test accuracy: 0.2683. Test F1: 0.2647\n",
      "Epoch 620. Loss: 0.6784. Test accuracy: 0.2293. Test F1: 0.2547\n",
      "Epoch 630. Loss: 0.6731. Test accuracy: 0.2585. Test F1: 0.2621\n",
      "Epoch 640. Loss: 0.6738. Test accuracy: 0.3707. Test F1: 0.2873\n",
      "Epoch 650. Loss: 0.7177. Test accuracy: 0.3902. Test F1: 0.2331\n",
      "Epoch 660. Loss: 0.6692. Test accuracy: 0.3171. Test F1: 0.2632\n",
      "Epoch 670. Loss: 0.6653. Test accuracy: 0.3805. Test F1: 0.2485\n",
      "Epoch 680. Loss: 0.6633. Test accuracy: 0.5024. Test F1: 0.2500\n",
      "Epoch 690. Loss: 0.6683. Test accuracy: 0.2829. Test F1: 0.2759\n",
      "Epoch 700. Loss: 0.6870. Test accuracy: 0.4878. Test F1: 0.2446\n",
      "Epoch 710. Loss: 0.6728. Test accuracy: 0.3512. Test F1: 0.2486\n",
      "Epoch 720. Loss: 0.6749. Test accuracy: 0.3366. Test F1: 0.2766\n",
      "Epoch 730. Loss: 0.6639. Test accuracy: 0.4976. Test F1: 0.2482\n",
      "Epoch 740. Loss: 0.6533. Test accuracy: 0.3610. Test F1: 0.2428\n",
      "Epoch 750. Loss: 0.6630. Test accuracy: 0.4244. Test F1: 0.2625\n",
      "Epoch 760. Loss: 0.6652. Test accuracy: 0.3268. Test F1: 0.2812\n",
      "Epoch 770. Loss: 0.6684. Test accuracy: 0.3366. Test F1: 0.2842\n",
      "Epoch 780. Loss: 0.6667. Test accuracy: 0.3707. Test F1: 0.2712\n",
      "Epoch 790. Loss: 0.6560. Test accuracy: 0.2927. Test F1: 0.2714\n",
      "Epoch 800. Loss: 0.6602. Test accuracy: 0.3610. Test F1: 0.2919\n",
      "Epoch 810. Loss: 0.6709. Test accuracy: 0.2195. Test F1: 0.2593\n",
      "Epoch 820. Loss: 0.6814. Test accuracy: 0.3951. Test F1: 0.2791\n",
      "Epoch 830. Loss: 0.6721. Test accuracy: 0.4244. Test F1: 0.2892\n",
      "Epoch 840. Loss: 0.6753. Test accuracy: 0.2634. Test F1: 0.2634\n",
      "Epoch 850. Loss: 0.6450. Test accuracy: 0.3561. Test F1: 0.2903\n",
      "Epoch 860. Loss: 0.6928. Test accuracy: 0.2829. Test F1: 0.2687\n",
      "Epoch 870. Loss: 0.6397. Test accuracy: 0.3854. Test F1: 0.2841\n",
      "Epoch 880. Loss: 0.6389. Test accuracy: 0.4049. Test F1: 0.2738\n",
      "Epoch 890. Loss: 0.6412. Test accuracy: 0.3122. Test F1: 0.2769\n",
      "Epoch 900. Loss: 0.6537. Test accuracy: 0.2780. Test F1: 0.2673\n",
      "Epoch 910. Loss: 0.6641. Test accuracy: 0.2927. Test F1: 0.2640\n",
      "Epoch 920. Loss: 0.6541. Test accuracy: 0.2976. Test F1: 0.2727\n",
      "Epoch 930. Loss: 0.6546. Test accuracy: 0.3512. Test F1: 0.2888\n",
      "Epoch 940. Loss: 0.6561. Test accuracy: 0.4439. Test F1: 0.2692\n",
      "Epoch 950. Loss: 0.6746. Test accuracy: 0.3951. Test F1: 0.2619\n",
      "Epoch 960. Loss: 0.6589. Test accuracy: 0.3610. Test F1: 0.2682\n",
      "Epoch 970. Loss: 0.6567. Test accuracy: 0.3902. Test F1: 0.2604\n",
      "Epoch 980. Loss: 0.6325. Test accuracy: 0.3610. Test F1: 0.2682\n",
      "Epoch 990. Loss: 0.6413. Test accuracy: 0.3561. Test F1: 0.2584\n"
     ]
    }
   ],
   "source": [
    "model = train(data, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674932e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check tensorboard.\n",
    "\n",
    "# try different hidden dimensions\n",
    "# standardising edge weights.\n",
    "# trying different optimizing schedules, learning rate scheduler, \n",
    "# early stopping.\n",
    "# Try GraphConv, and other layers, pass edge_weights\n",
    "# different layernorm, different dropouts\n",
    "# should add lin layers?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5340_env",
   "language": "python",
   "name": "cs5340_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
