{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This implements the iterative classification algorithm as described in slide 37 of http://web.stanford.edu/class/cs224w/slides/05-message.pdf  \n",
    "It classifies a node based on its features as well as labels of neighbours\n",
    "\n",
    "## Definitions\n",
    "$v$: Node  \n",
    "$Y_v$: Labels of node $v$  \n",
    "$f_v$: feature vector of node $v$  \n",
    "$z_v$: summary of labels of $v$'s neighbours (a vector)  \n",
    "$\\phi_1(f_v)$: predict node label based on node feature vector $f_v$  \n",
    "$\\phi_2(f_v, z_v)$: predict label based on node feature vector $f_v$ of labels of $v$'s neighbours\n",
    "\n",
    "## Phase 1: Train a Classifier based on node attributes only\n",
    "The classifier can be linear classifier, neural network classifier etc. This is trained on the training set to predict the labels for each node.\n",
    "\n",
    "$\\phi_1(f_v)$ : to predict $Y_v$ based on $f_v$  \n",
    "$\\phi_2(f_v, z_v)$ to predict $Y_v$ based on $f_v$ and summary $z_v$ of labels of $v$'s neighbours  \n",
    "For vector $z_v$ of neighbourhood labels, let\n",
    "\n",
    "- $I$ = incoming neighbour label info vector  \n",
    "  $I_0$ = 1 if at least one of the incoming node is labelled 0.  \n",
    "  $I_1$ = 1 if at least one of the incoming node is labelled 1.\n",
    "- $O$ = outgoing neighbour label info vector  \n",
    "  $O_0$ = 1 if at least one of the outgoing node is labelled 1.  \n",
    "  $O_1$ = 1 if at least one of the outgoing node is labelled 1.\n",
    "\n",
    "## Phase 2: Iterate till Convergence\n",
    "\n",
    "On the test set, set the labels based on the classifier in Phase 1,\n",
    "\n",
    "## Step 1: Train Classifier\n",
    "\n",
    "On a different training set, train two classifiers:\n",
    "\n",
    "- node attribute vector only: $\\phi_1$\n",
    "- node attribute and link vectors: $\\phi_2$\n",
    "\n",
    "## Step 2: Apply Classifier to test set\n",
    "\n",
    "On test set, use trained node feature vector classifier $\\phi_1$ to set $Y_v$\n",
    "\n",
    "## Step 3.1: Update relational vectors z\n",
    "\n",
    "Update $z_v$ for all nodes on test set\n",
    "\n",
    "## 3.2: Update Label\n",
    "\n",
    "Reclassify all nodes with $\\phi_2$\n",
    "\n",
    "## Iterate\n",
    "\n",
    "Continue until convergence\n",
    "\n",
    "- update $z_v$\n",
    "- update $Y_v = \\phi_2(f_v, z_v)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collective.constants import get_summary_zv\n",
    "from collective.Iterative import IterativeClassification\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node = pd.read_csv('../data/unified_node_data.csv', keep_default_na=False)\n",
    "df_edge = pd.read_csv('../data/max_edge_weights.csv')\n",
    "df_formatted = preprocess.nodes1(df_node)\n",
    "df_clean = preprocess.nodes_filter(df_formatted, df_edge)\n",
    "df_impute = preprocess.impute(df_clean)\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = preprocess.stratified_train_val_test_split(df_impute)\n",
    "X_test = pd.concat([X_val, X_test])\n",
    "y_test = pd.concat([y_val, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further cleaning\n",
    "Note that need to drop confessed_assignments and num_confessed_assignments as both indicates whether the student cheated or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, y_train], axis = 1)\n",
    "X_train['label'] = X_train['num_confessed_assignments'].apply(lambda x : 1 if x > 0 else 0)\n",
    "X_train = X_train.drop(['num_confessed_assignments', 'confessed_assignments'], axis = 1)\n",
    "\n",
    "X_test = pd.concat([X_test, y_test], axis = 1)\n",
    "X_test['label'] = X_test['num_confessed_assignments'].apply(lambda x : 1 if x > 0 else 0)\n",
    "X_test = X_test.drop(['num_confessed_assignments', 'confessed_assignments'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_graph = nx.Graph()\n",
    "for index, row in X_train.iterrows():\n",
    "    network_graph.add_node(row['name'])\n",
    "    network_graph.nodes[row['name']].update(row.drop(['name']).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'jessica_torres'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_edge[df_edge.NodeID2 == 'jessica_mack'].iloc[0].NodeID1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in network_graph.nodes:\n",
    "    edge1 = df_edge[df_edge.NodeID1 == node]\n",
    "    edge2 = df_edge[df_edge.NodeID2 == node]\n",
    "    if (len(edge1) != 0):\n",
    "        for index, edge in edge1.iterrows():\n",
    "            if (edge.NodeID2 in network_graph.nodes):\n",
    "                network_graph.add_edge(node, edge.NodeID2)\n",
    "                network_graph[node][edge.NodeID2]['edge_weight'] = edge.edge_weights\n",
    "    elif (len(edge2) != 0):\n",
    "        for index, edge in edge2.iterrows():\n",
    "            if (edge.NodeID1 in network_graph.nodes):\n",
    "                network_graph.add_edge(node, edge.NodeID1)\n",
    "                network_graph[node][edge.NodeID1]['edge_weight'] = edge.edge_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a networkx graph using the edgelist and setting the edge weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_graph = nx.from_pandas_edgelist(df_edge, \"NodeID1\", \"NodeID2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in network_graph.edges:\n",
    "    edge1 = df_edge[(df_edge.NodeID1 == edge[0]) & (df_edge.NodeID2 == edge[1])]\n",
    "    edge2 = df_edge[(df_edge.NodeID1 == edge[1]) & (df_edge.NodeID2 == edge[0])]\n",
    "    if (len(edge1) == 1):\n",
    "        network_graph[edge[0]][edge[1]]['edge_weight'] = edge_data[(edge_data.NodeID1 == edge[0]) & (edge_data.NodeID2 == edge[1])].iloc[0]['edge_weights']\n",
    "    elif (len(edge2) == 1):\n",
    "        network_graph[edge[0]][edge[1]]['edge_weight'] = edge_data[(edge_data.NodeID1 == edge[1]) & (edge_data.NodeID2 == edge[0])].iloc[0]['edge_weights']\n",
    "    else:\n",
    "        print(\"error: \" + str(edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0076399961214356875"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_graph[\"joseph_trevino\"]['aaron_christian']['edge_weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting the node attributes of the networkx graph using the node data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(network_graph, X_train.set_index(\"name\").to_dict(\"index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'year_of_study': 1,\n",
       " 'participation': 3.0000000000000004,\n",
       " 'pe_percent': 0.2333333333333333,\n",
       " 'finals_percent': 0.4,\n",
       " 'midterms_percent': 0.12853934181648263,\n",
       " 'afast': 0,\n",
       " 'level_min_max': 0.7600000000000001,\n",
       " 'exp_min_max': 0.6643572276410178,\n",
       " 't01_exp': 240,\n",
       " 't02_exp': 260,\n",
       " 't03_exp': 240,\n",
       " 't04_exp': 250,\n",
       " 't05_exp': 225,\n",
       " 't06_exp': 225,\n",
       " 't07_exp': 250,\n",
       " 't08_exp': 250,\n",
       " 't09_exp': 275,\n",
       " 't10_exp': 250,\n",
       " 'num_videos': 1,\n",
       " 'avg_videos_completion': 0.0,\n",
       " 'batch_1821': 1,\n",
       " 'batch_1935': 0,\n",
       " 'batch_2023': 0,\n",
       " 'major_-': 0,\n",
       " 'major_Business Analytics': 0,\n",
       " 'major_Chemistry': 0,\n",
       " 'major_Computational Biology': 0,\n",
       " 'major_Data Science and Analytics': 0,\n",
       " 'major_Faculty of Arts & Social Sci': 0,\n",
       " 'major_Faculty of Engineering': 0,\n",
       " 'major_Faculty of Law': 0,\n",
       " 'major_Faculty of Science': 0,\n",
       " 'major_Life Sciences': 0,\n",
       " 'major_Math/Applied Math': 0,\n",
       " 'major_NUS Business School': 0,\n",
       " 'major_Pharmacy': 0,\n",
       " 'major_Physics': 0,\n",
       " 'major_Quantitative Finance': 0,\n",
       " 'major_School of Computing': 0,\n",
       " 'major_School of Design & Environment': 0,\n",
       " 'major_Statistics': 1,\n",
       " 'major_Yong Loo Lin School (Medicine)': 0,\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_graph.nodes[\"joseph_trevino\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gets L1_max, L0_max, L1_mean, L0_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-ff368f473c33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnetwork_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_summary_zv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\University\\Masters\\Y2 Sem 2\\CS5340\\Project\\bayesian_beats_cheats\\iterative_yyy\\collective\\constants.py\u001b[0m in \u001b[0;36mget_summary_zv\u001b[1;34m(networkx_graph)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mneighbor_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetworkx_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0medge_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnetworkx_graph\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mneighbor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'edge_weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mneighbor_node\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                 \u001b[0mL1_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL1_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mL1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mL1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'"
     ]
    }
   ],
   "source": [
    "network_graph = get_summary_zv(network_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for node in network_graph.nodes:\n",
    "    network_graph.nodes[node]['index'] = node\n",
    "    temp = pd.DataFrame([network_graph.nodes[node]]).set_index('index')\n",
    "    df = pd.concat([df, temp])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Logistic Regression without L1_max, L0_max, L1_mean, L0_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Doing train-test-split\")\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# model1\n",
    "print(\"Training model1\")\n",
    "train_x_model1 = train.drop(\n",
    "    ['L1_max', 'L0_max', 'L1_mean', 'L0_mean', 'label'], axis=1)\n",
    "train_y_model1 = train['label']\n",
    "test_x_model1 = test.drop(\n",
    "    ['L1_max', 'L0_max', 'L1_mean', 'L0_mean', 'label'], axis=1)\n",
    "test_y_model1 = test['label']\n",
    "model1 = LogisticRegression(max_iter=10000)\n",
    "model1.fit(train_x_model1, train_y_model1)\n",
    "y_pred1 = model1.predict(test_x_model1)\n",
    "\n",
    "print(accuracy_score(test_y_model1.to_numpy(), y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Logistic Regression with L1_max, L0_max, L1_mean, L0_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training model2\")\n",
    "train_x_model2 = train.drop(['label'], axis=1)\n",
    "train_y_model2 = train['label']\n",
    "test_x_model2 = test.drop(['label'], axis=1)\n",
    "test_y_model2 = test['label']\n",
    "model2 = LogisticRegression(max_iter=10000)\n",
    "model2.fit(train_x_model2, train_y_model2)\n",
    "y_pred2 = model2.predict(test_x_model2)\n",
    "\n",
    "print(accuracy_score(test_y_model2.to_numpy(), y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Iterative classification\")\n",
    "ic = IterativeClassification(max_iterations=5)\n",
    "new_gnx = ic.predict(network_graph, model1, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_gnx_pred = pd.DataFrame([])\n",
    "for node in test['label'].index:\n",
    "    temp = pd.DataFrame([[new_gnx.nodes[node]['label'][0], node]], columns=[\n",
    "                        'label', 'index']).set_index('index')\n",
    "    new_gnx_pred = pd.concat([new_gnx_pred, temp])\n",
    "print(accuracy_score(test_y_model2.to_numpy(), new_gnx_pred.to_numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
